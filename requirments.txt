Data mining project - first checkpoint

Choose a website that contains data (a lot) which is not publicly available via an API. The data should keep being updated frequently, and every data point (a news article / a weather prediction / a movie review) should contain as much details as possible). ​Be creative!
Confirm your data source with one of the tech mentors before going to the next step.
Read through ​this tutorial​, or watch ​this video​ (or both) to learn about the requests package of Python that allows you to send requests and get responses from web servers.
Read through ​this tutorial​, or ​watch this​ video to learn about the beautifulsoup package of Python that allows you to parse the response.
Code your own web scraper. You’re required to adhere to conventions and write clean and quality well-structured code. The web scraper should be able to query your data source and print the collected data to the screen. You should be able to change the settings of the web scraper according to your needs.
You can only use requests and bs4 packages, and selenium if needed.
Add a README.md file that explains what website you are using, how did you go about solving the problem, how to run your code etc. It should give all the information necessary to users that just got your code and want to use it to scrape. (As a reference, you can use https://www.makeareadme.com/.)
Add a requirements.txt file with all the installations required with pip on top of bare Python installation to allow your code to run.


Good luck!
